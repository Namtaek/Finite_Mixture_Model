---
title: "NBA_Salary"
output: html_document
---


2017~2018 시즌 NBA선수들의 연봉 데이터를 통해, 어떤 지표들이 선수들의 연봉에 영향을 미치는가 알아보고자 한다.  선수들의 활약을 평가하는 다양한 지표들이 있지만, 어떤 지표들이 결정적이며, 거기에 해당하는 선수유형에 대한 추론을 할 수 있도록 해석가능한 모형을 만들겠다. 이를 위해 다중 회귀 분석을 할 생각이고, 다양한 변수들 중 필요한 경우 변수를 선택할 수 있는 방법들을 활용하겠다. 


**데이터 불러오기**

```{r}
library(readxl)
nba.data <- read_excel("C:/Users/lenovo/Desktop/Statistics/Rstudy/week3/2017-18_NBA_salary.xlsx")
# Kaggle에 게시되어 있는 NBA Salary 데이터를 사용했다.
```


```{r}
colnames(nba.data)
```
"player" - character  
"salaries" - numeric  
"NBA_Country" - character  
"NBA_DraftNumber" - Numeric  
"Age" - numeric  
"Tm" - character  
"G" - numeric : 게임수  
"MP" - numeric : 몇분을 뛰었는가  
"PER" - numeric : 1분당 얼마나....선수의 효율성을 판단하는 2차지표  
"TS%" - numeric : True Shooting Percentage  
"3PAr" - numeric : 3점슛 성공률...? 커리가 높은거 보니 맞는듯  
"FTr" - numeric : 자유투를 얼마나 잘 얻어내는가  
"ORB%" - numeric : Offensive Rebound Percentage  
"DRB%" - numeric : Deffensive Rebound Percentage   
"TRB%" - numeric : Total Rebound Percentage  
"AST%" - numeric : Assist Percentage  
"STL%" - numeric : Steal Percentage - 스틸로 공격을 끝낸 비율,  
"BLK%" - numeric : Block  
"TOV%" - numeric : Turnover Percentage      
"USG%" - numeric : Usage Rate - 선수가 얼마나 많은 공격권을 가지는가, 공을 가지고 플레이하는 비중  
"OWS" - numeric : Offensive win share  
"DWS" - numeric : Deffensive Win Share  
"WS" - numeric : Win Share  
"WS/48" - numeric           
"OBPM" - numeric : Offensive Box Plus/Minus  
"DBPM" - numeric : Deffensive Box Plus/Minus  
"BPM" - numeric : Box Plus/Minus  
"VORP" - numeric : Value over Replacement Player - 다른 가상의 선수보다 얼마나 더 나은 가치를 지니는가


각 Column의 이름과 자료구조, 의미하는 바를 정리하였다.  
총 28개의 열이 있고, 이중에 3개의 열은 numeric이 아니다.  
농구에 익숙하지 않은 사람들은 이해하기 어려운 지표들도 많기 때문에, 이를 유의하여 해석해야하겠다.  

```{r}
dim(nba.data) # 485행 28열
summary(nba.data)
str(nba.data)
# 데이터에 대한 요약
```


**1. 데이터 전처리**

이제 주어진 자료를 내가 원하는대로 변형하고자 한다.  
1) 결측치는 필요한 경우 제거해야 한다.  
2) 선수이름은 변수라기보단 행의 이름으로 가야 한다.  
3) 관측치가 485개이기 때문에, "NBA_Country"라는 범주형 변수는 자유도를 위해 삭제가능할 경우 삭제하고 싶다. 
4) 관측된 값들 중, 누가봐도 잘못 입력된 값이 있는지 확인한다.  
5) Team에 따른 효과는 궁금하지 않다. NBA는 흔히 생각하는 축구와는 다른 연봉 체계를 지니고, 샐러리캡이 정해져 있기 때문에, 각 선수들은 팀이라는 변수 안에 Nested 되어있지만, 이 모든 것을 고려한 모형을 세울 자신이 없다.  

이 네가지를 바탕으로 데이터를 가공할 것이다. 결측치를 먼저 제거하는 이유는, 실제 전처리 과정에서 선수명을 rownames으로 바꿔주고 결측치를 제거하면 rowname이 다시 숫자로 바뀌는 일이 발생해서 편의상 그렇게 진행한다.

```{r}
#결측치 먼저 제거하자
table(is.na(nba.data)) #8개의 결측치
a = NULL
for(i in 1:28) {
  a <- c(a, sum(is.na(nba.data[, i]))) # 결측치가 어디 있는지 찾아보자
}
a 
which(a == 2) # 10, 11, 12, 19열에 각각 2개씩의 NA
which(is.na(nba.data[, c(10, 11, 12, 19)]))
```

어디에 NA가 있는지 알았기 때문에 직접 데이터에서 확인해보자.  
결측치를 지울 수 있는지, 아니면 다른 방법을 적용해야하는지 직접 확인한다.  


```{r}
View(nba.data[30, ]) # 출전수가 워낙 적어서 NA발생, 빼도 된다고 생각
```


```{r}
nba.data <- nba.data[complete.cases(nba.data), ] # 결측치 제거
dim(nba.data) # 483행 28열로 감소
```

결측치를 제거했으니, 이제 다른 작업들을 이어가자.  
선수 이름을 기존에 변수에서, rowname으로 바꿔주자.  

```{r, eval = F}
rownames(nba.data) <- nba.data$Player # 숫자가 다르다고? 같은 이름이 있는건가
```

바로 넣을 경우, 오류가 발생한다. 동명이인이 있을 수 있으니, 확인과정을 거치자.  

```{r}
length(rownames(nba.data))
which(table(nba.data$Player) > 1)
# Kay Felder라는 선수가 문제가 된다.
which(nba.data$Player == "Kay Felder")
# Kay Felder가 현재 3명이나 관측된다.
View(nba.data[c(223:225), ]) 
```

찾아보니까 Kay Felder가 3개들어가 있는데, 다른사람이 아니고 한사람이다.  
데이터를 합치는 과정에 문제가 있었는지, 223행에는 1경기를 뛰었고, 224행에는 15경기를 뛰었으며, 225행에서는 16경기를 뛰었다. 근데 1경기와 15경기의 기록을 합치면 16경기의 기록과 정확히 일치한다.  
그러므로 앞의 두 행은 삭제할 수 있다.

```{r}
nba.data <- nba.data[-c(223:224), ] #겹치는거 삭제
dim(nba.data) # 481행 28열으로 감소
rownames(nba.data) <- nba.data$Player #행이름 바꿔줌
head(rownames(nba.data)) # 확인
```

선수 이름이 rowname으로 잘 들어갔다.

```{r}
nba.data$Player <- NULL # player 열 삭제
nba.data$Tm <- NULL #팀의 효과는 관심없음, 팀의 순위도 아니고 그냥 팀...
dim(nba.data) # 481행 26열로 감소
```

변수를 현재 2개를 감소시켰다.  
또한 잘못 입력된 값이 있는지 직접 확인했는데, `PER`같이 음수의 값을 갖는 지표들이 있었으나,  
음수를 가질 수 있는 경우였고, 추가적인 정제는 필요해보이지 않는다.  
이제 `선수의 출신국가`라는 요인이 유의미한지 확인하자.  

국가 변수가 있는 경우와 없는 경우에 대해 ANOVA를 실행할 계획이다.  
미국인이 아닌 선수들중 슈퍼스타들도 NBA에 되게 많기 때문에, 
아마 통계적으로 유의한 수준의 차이는 없을 것 같다.  
그 예시로 이번 NBA 시즌 MVP는 그리스 출신의 아데토쿤보이다.

```{r}
# 국가 요인의 효과가 유의미한지 ANOVA를 해보자
no <- lm(Salary ~ . -NBA_Country , data = nba.data)
yes <- lm(Salary ~ ., data = nba.data)
anova(no, yes) #둘에 차이가 없다. 그러면 그냥 지워버리자
nba.data$NBA_Country <- NULL
dim(nba.data) # 최종 481행 25열
```

최종적으로 우리의 데이터는 481개의 관측치와 25개의 변수를 갖는 데이터로 바뀌었다.


**2. 연봉의 분포와 회귀진단**

연봉의 분포을 알아보고, 이를 바탕으로 회귀모형의 가정들을 어떻게 만족시밀 수 있을지 인사이트를 얻어내야 한다. 보통 연봉은 왼쪽으로 치우친, 일부 고연봉자들의 효과로 평균이 중앙값보다 높은 경향을 가진다. 여기서는 어떻게 분포하는지 알아보자. Boxplot과 히스토그램을 통해 확인하자.

```{r}
library(ggplot2)
ggplot(nba.data, aes(x = 1, y = Salary)) + geom_boxplot(aes(fill = 1, alpha = 0.7)) + 
  coord_flip() + geom_jitter(width = 0.1)
ggplot(nba.data, aes(x = Salary)) + geom_histogram(bins = 30)
```

이 경우에도 확실히 왼쪽으로 치우쳐져있고, Y값에 대한 변환(로그 혹은 제곱근)이 필요함을 생각하자. 일단 회귀모형에 넣어보고 판단하자.

```{r}
salary.reg <- lm(Salary ~ ., data = nba.data)
summary(salary.reg) 
```

유의미한 변수가 몇개 없다. 관측치가 엄청 많지 않기때문인지, R스퀘어 값도 0.55정도로 낮다.  

```{r}
par(mfrow = c(2,2))
plot(salary.reg) # 등분산, 정규성 등등 다 에바인데...?
par(mfrow = c(1,1))
```

잔차의 분포가 Megaphone shape이기 때문에, 등분산성을 만족하지 못한다. 또한 QQplot상에서 선을 벗어나는 점이 되게 많다. 정규성 또한 만족하지 못하기때문에 변환이 필요하다. 등분산성을 맞춰주려면 Variance Stablizing Transformation(VST)를 시행할 수 있지만, 최적의 VST가 무엇인지 생각해내기는 어렵다. 이를 위한 패키지를 불러오자.

```{r}
library(car)
```

`car` 패키지는 최적의 VST를 찾아주는 함수를 내장하고 있다. 이를 활용하자.

```{r}
summary(car::powerTransform(nba.data$Salary)) 
# salary ^ 0.2를 써라 by LRT
nba.data2 <- nba.data 
nba.data2$Salary <- (nba.data2$Salary)^0.2  # Y값을 바꾸자
```

`nba.data2`에 바뀌 Y값을 저장해두자. 이후에 nba.data를 사용해야 할 수도 있으니까.

```{r}
root.salary.reg <- lm(Salary ~ ., data = nba.data2) # 바꿔서 회귀
par(mfrow = c(2, 2))
plot(root.salary.reg)
par(mfrow = c(1, 1))
ncvTest(root.salary.reg) #등분산성 만족
```

plot 상으로, 등분산성과 정규성을 모두 만족하는 것으로 보인다. 실제로 등분산성검정을 실행할 경우, 등분산이라는 가설을 기각하지 못한다. 하지만 좀 더 정확히 회귀 가정들을 검정하고 싶으므로, 다른 패키지를 사용한다.

```{r}
library(gvlma)
```

`gvlma` 패키지는 등분산성, 정규성등 회귀분석의 가정들을 한번에 확인할 수 있는 패키지이다.

```{r}
gvmodel <- gvlma(root.salary.reg)  
summary(gvmodel)
```

회귀가정들을 만족함을 볼 수 있다.  

하지만 변수가 많고, 그중에 비슷한 의미를 갖는 변수가 있기 때문에 분명히 다중공선성이 있을 것이다.

```{r}
vif(root.salary.reg)
```

미친듯한 다중공선성이 있음을 확인가능하다. 보다 직관적으로 어떤 변수들간에 상관관계가 있는지 파악하자. 왜냐하면 이후 변수 선택을 통한 모형들이 만들어질텐데, 모형간에 error를 비교함과 동시에 이 상관관계를 바탕으로 어떤 모형이 더 좋은지 판단할 수 있을 것이다.

```{r}
library(ggcorrplot)
corr <- cor(nba.data) # 상관계수 행렬
p_mat <- cor_pmat(nba.data) # 상관계수 p-value 행렬
ggcorrplot(corr, hc.order = T, type = "lower", 
           outline.color = "white", ggtheme = ggplot2::theme_gray(), 
           colors = c("#6D9EC1", "white", "#E46726"), lab = T, p.mat = p_mat,
           insig = "blank", lab_size = 2, tl.cex = 7)
```

상관계수행렬을 시각화하고, 거기서 상관계수가 0임을 기각하지 못하는 값들은 공백으로 남겨두었다. WS와 OWS, Game과 MP같이 유사한 지표간의 상관관계가 매우 높게 나타나고, 변수들의 측정 방법간 유사함 때문에 다중공선성이 발생함.

그렇다면 어떻게 변수선택을 해야, 우리가 원하는 목적(어떤 지표가 연봉에 영향을 미치는가)에 다가갈 수 있을까?

*1) Best Subset Selection*
*2) Lasso Regression*

1) Best Subset Selection은 가능한 모든 변수의 조합중에서 어떤 변수간의 조합이 가장 낮은 AIC, BIC, Cp 값을 갖는지에 따라 판단하는 방법이다. 변수가 40개가 넘어갈 경우, 컴퓨터로 계산하기 어려워지지만, 현재 25개의 변수이기 때문에 사용가능하다.

2) Lasso는 Ridge와 유사하게 Beta계수에 페널티를 적용하여 변수를 선택하는 방법이다. 다중공선성이 뚜렷할 때 사용하면, 기존에 역행렬을 갖지 못해서 LSE를 통해 구할수 없던 Beta_hat을 구할 수 있다. 비록 역행렬이 존재해 LSE를 구할수 있더라도, Ridge나 Lasso의 예측력이 훨씬 좋아진다. 또한 Ridge와 다르게 페널티가 커질수록 많은 Beta값이 0을 갖기 때문에 변수선택에도 좋다.

이 두 방법들을 사용해서, 어떤 방법이 더 작은 Cross-Valiation Error를 갖는지 일차적으로 판단할 수 있겠다.


**3. 모델 적합과 선택**

*Best Subset Selection*

Best Subset Selection을 위해서 `leaps`패키지를 불러온다.
```{r}
library(leaps)
```

`regsubset`함수는 변수의 개수마다 최적의 선택을 보여준다. 같은 변수 숫자안에서는 RSS가 가장 작은 변수 조합을 고른다. `nvmax` argument는 몇개까지의 조합을 확인할 것인지 지정한다. 여기서는 20개까지 확인하겠다. 각각의 변수 개수에서 최적을 고를때는, AIC BIC Cp 등등으로 비교한다.

```{r}
best <- regsubsets(Salary ~ ., data = nba.data2, nvmax = 20)
summary(best)
best.statistics <- summary(best)
```


```{r}
plot(best.statistics$rss,xlab="Number of Variables",ylab="Cp",type='l') 
# 변수가 많을수록 training Rss는 작아짐
```

```{r}
par(mfrow = c(1, 2))
plot(best.statistics$cp,xlab="Number of Variables",ylab="Cp",type='l')
l = which.min(best.statistics$cp)
points(l,best.statistics$cp[l],col="red",cex=2,pch=20) # cp 통계량이 가장 작은 변수숫자는 12개

plot(best.statistics$bic,xlab="Number of Variables",ylab="Cp",type='l')
l = which.min(best.statistics$bic)
points(l,best.statistics$bic[l],col="red",cex=2,pch=20) # bic 통계량이 가장 작은 변수숫자는 5개
par(mfrow = c(1,1))
```

BIC는 복잡한 모형에 더 큰 페널티를 주는 것으로 알려져 있다. 또한 우리의 목적을 위해선 해석가능한 모형을 선택해야 하기때문에, BIC에 따라서 변수숫자가 적은 모형을 선택하자.

```{r}
coef(best, 5) 
# NBA_DraftNumber + Age + G + MP + DRB로 만들어진다
colnames(nba.data2)[11] <- "DRB" 
best.reg <- lm(Salary ~ NBA_DraftNumber + Age + G + MP + DRB, data = nba.data2)
summary(best.reg)
```

Best Subset Selection으로 구해진 결과를 보면, 모든 변수는 유의미하게 나온다. 이제 이 변수선택된 모형으로 CV Error를 구해야한다.

**하지만** 이런 과정에는 오류가 있다. 이것이 정확히 오류인지 확신할 수 없지만, 아마 잘못되었을 것이다. 그리고 어떻게 구현해야할지 잘 모르겠으니 고치지 않고 가겠지만 설명만 적어둡니다....
CV error를 구할때 2)모델적합에 대한 error만을 구해서는 안되고, 1)변수선택 과정까지 포함한 과정이 Cross Validation 과정에 포함되어야 한다. 선택된 변수로 모델적합에 대한 error를 구하면 error가 underestimated한다고 알려져 있다. 이 점을 고려해서 판단하자.


Training set과  Test set으로 나눠서 MSE를 구할수도 있지만, CV를 이용하는 이유는 다음과 같다.  
1) 다중공선성때문에 XtX의 역행렬이 존재하지 않는것 같다. 예를 들어 G와 MP간에는 선형관계가 크고(Column이 Linear Dependent할 것), 아마 그래서 `solve`함수가 작동하지 않는다. 그래서 CV를 통해 시도했을때는 잘 작동했다.  
2) 변수에 비해 관측치가 많은 편이라고 생각되지 않는다. 데이터가 부족해 데이터셋을 분할할 경우, Error가 갖는 분산이 커질 가능성이 높다.(분산이 재현되지 않는다.)

CV Error를 직접 구하기 위해서는 `cvTools` 패키지를 사용해야한다.
```{r}
library(cvTools)
```

시드를 지정하고, 이에 모든 변수를 적합시켰을때의 Test MSE를 구해보자

```{r}
set.seed(707)
all.cv <- cvFit(root.salary.reg, data = nba.data2, y = nba.data$Salary, cost = mspe, K = 5)
all.cv
```

Test MSE가 말도 안되게 크다. Overfitting 되었으며, 다중공선성으로 인해 분산이 엄청나게 크기 때문이라고 생각할 수 있다.  
Best Subset Selection에 따른 Test MSE를 구해보자

```{r}
set.seed(707)
cv.lm <- cvFit(best.reg, data = nba.data2, y = nba.data2$Salary, cost = mspe, K = 5)
cv.lm 
```

Best Subset Selection에 따른 Test MSE는 14.26429가 나온다. 이는 Underestimated된 값일 가능성이 높음을 생각하자.


*Lasso Regression*

라쏘에 대한 설명은 여기에 잘 되어 있다. http://www.datamarket.kr/xe/board_BoGi29/7176

바로 CV를 구할 수 있지만, 데이터셋을 나눠서 하는 방법을 시행한 후, CV방법으로 가겠다.  

```{r}
set.seed(707)
dim(nba.data2)
n <- NROW(nba.data2)
index <- sample(1:n, 350, replace = F)
train <- nba.data2[index, ]
test <- nba.data2[-index, ]
```

시드를 지정하고, 데이터셋을 training set과 test set으로 분리했다.

```{r}
tr.x <- model.matrix(Salary ~ ., data = train)[, -1]
tr.x[1:5, ]
tr.y <- train$Salary
te.x <- model.matrix(Salary ~ ., data = test)[, -1]
te.y <- test$Salary
```

Ridge나 Lasso를 위한 패키지는 `glmnet`이다.
```{r}
library(glmnet)
```

`glmnet` 함수에서 `alpha = 1`로 지정하면 lasso이며, `alpha = 0`이면 ridge이다.

```{r}
grid = c(10^seq(1, -3, length = 100), 0) #다양한 람다값을 지정해놓고, 여기서 최소인것을 뽑자
lasso <- glmnet(tr.x, tr.y, alpha = 1, lambda = grid) # 여러 lasso 회귀 실행
coef.lasso <- coef(lasso)
te.yhat <- predict(lasso, s = grid, newx = te.x)
te.mse = function (yhat,y) mean((y - yhat)^2)
mse <- apply(te.yhat, 2, te.mse, y = te.y)
plot(1:101,mse,type='l',col='red',lwd=2,xlab='Index of lambda',ylab='Test MSE') 
# test mse를 최소화시키는 lambda의 index를 보여줌
```

```{r}
l = which.min(mse)
lasso$lambda[l] # Test MSE를 최소화하는 람다 값은 0.152이다
round(coef(lasso)[ , l], 4)
```
많은 베타값들이 0이되면서, 자동적으로 변수가 선택되었다.

```{r}
lasso.testmse = mean((te.y - te.yhat)^2)
lasso.testmse 
```
Test MSE는 19.50678이다. Best Subset Selection과의 비교를 위해선 같이 cv error로 비교해야하니 cv를 통해 구해보자.

```{r}
set.seed(707)
log.salary <- nba.data2$Salary
hat.mat <- model.matrix(Salary ~ ., data = nba.data2)[, -1]
cv.lasso <- cv.glmnet(hat.mat, log.salary, nfolds = 5) 
```

`glmnet` 패키지에는 CV error를 자동으로 구해주는 `cv.glmnet`함수가 내장되어 있다.

```{r}
plot(cv.lasso)
cv.lambda <- cv.lasso$lambda.min
cv.lambda
```

아까는 0.152였지만, 지금은 0.217이다. 차이가 있을 수 있다.

```{r}
fit.lasso <- glmnet(hat.mat, log.salary, alpha = 1, lambda = cv.lambda)
coef(fit.lasso) # 위하고 변수 선택이 다른데, 여기가 좀더 믿을만한거같기도....농구 정확히 모름...
cv.lasso.testmse <- min(cv.lasso$cvm)
cv.lasso.testmse # 14.7918
```

CV Test error는 14.56707이다.


**4. 최종모형과 해석**

1) 모든 변수에 대한 cv error = 9.938824e+13  
2) subset selection에 대한 (Salary ~ NBA_DraftNumber + Age + G + MP + DRB)  
cv error = 14.26429   
3) lasso에 대한  (Salary ~ NBA_DraftNumber + Age + MP + DRB + USG + WS + VORP)
cv error = 14.56707  

2)의 error가 3)의 error보다 작지만, 3)번 모형을 선택하려 한다. 이유는 다음과 같다.

1. Subset Selection cv error에서는 변수 선택과정까지 고려하지 못한 cv error이므로, error가 underestimated 되었을 가능성이 높다.  
2. Subset Selection의 변수를 보면, G와 MP라는 매우 유사한 변수가 겹쳐서 나타난다. 사실상 변수 4개만으로 평가를 해야하는데, 경기의 지표에 대한 변수는 DRB하나라고 봐도 무방하다. 이럴경우 선수의 활약에 따른 연봉이라는 의미를 파악하는데에 어려움이 있을 것이다. 반면에 Lasso에서는 DRB, USG, WS, VORP와 같이 경기안에서 유의미한 지표들을 요약적으로 포함하고 있다는 판단이 가능할 것이다.

따라서 Lasso에 따른 모형을 선택하면  
log.Salary ~ 9.514 + -0.074 * NBA_DraftNumber + 0.362 * Age + 0.002 * MP +  
              0.048 * DRB + 0.002 * USG + 0.065 * WS + 0.361 * VORP
라는 회귀식이 만들어진다.     


가장 베타계수가 큰 VORP에 따라 데이터를 정렬시킬 경우, 르브론 제임스, 제임스 하든, 러셀 웨스트브룩, 데미안 릴라드, 아데토쿤보와 같이 팀의 에이스 선수들이 나온다. 이 선수들은 경기중에 볼을 소유하는 시간이 많으면서 동시에 공격을 전개하는 역할을 부여받는다. 이는 직관적으로 USG와도 연관되는 것이다. 둘의 상관관계는 0.3정도로 높지는 않다.  
또한 Win share와는 매우 큰 상관관계 0.91을 지니지만, WS의 계수를 낮게 보정해 다중공선성을 해결하는 lasso의 특성상 문제는 없을 것이다.  
또한 기량이 만개할 수록 나이가 들고, 한번 올라간 연봉은 내려가기 어려우므로, 나이 따라 연봉이 증가하는 것도 맞다고 판단할 수 있다.  






























